{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5181227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.build import bulk\n",
    "import io\n",
    "from ase.visualize import view\n",
    "from ase.io import read, write\n",
    "import numpy as np\n",
    "import os\n",
    "import fileinput\n",
    "from shutil import rmtree\n",
    "from shutil import copyfile\n",
    "from ase.phonons import Phonons\n",
    "import matplotlib.pyplot as plt\n",
    "from ase.build import make_supercell\n",
    "from ase.optimize import LBFGS\n",
    "from acease.ace_calculator import ACEpotentials, initialize_julia, set_params\n",
    "from ase.constraints import UnitCellFilter\n",
    "from ase.units import J\n",
    "from ase.constraints import FixCartesian\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/f/PhD/ace_pot/model.json\"\n",
    "python_path = \"/home/f/PhD/env/bin/python\"\n",
    "file_path_0 = '/home/f/PhD/ace_pot/main_model_just_connor.csv'\n",
    "file_path_1 = '/home/f/PhD/ace_pot/20_percent_models_all_plannar_defects/final_model_no_stack_no_twin.csv'\n",
    "file_path_2 = '/home/f/PhD/ace_pot/20_percent_models_all_plannar_defects/final_model_no_twin.csv'\n",
    "file_path_3 = '/home/f/PhD/ace_pot/20_percent_models_all_plannar_defects/final_model_no_twin_active_learned.csv'\n",
    "m1 = '/home/f/PhD/ace_pot/five_models_no_defects/coeffs_subset_1.csv'\n",
    "m2 = '/home/f/PhD/ace_pot/five_models_no_defects/coeffs_subset_2.csv'\n",
    "m3 = '/home/f/PhD/ace_pot/five_models_no_defects/coeffs_subset_3.csv'\n",
    "m4 = '/home/f/PhD/ace_pot/five_models_no_defects/coeffs_subset_4.csv'\n",
    "m5 = '/home/f/PhD/ace_pot/five_models_no_defects/coeffs_subset_5.csv'\n",
    "g1 = '/home/f/PhD/ace_pot/five_models_stacking_faults/coeffs_subset_1.csv'\n",
    "g2 = '/home/f/PhD/ace_pot/five_models_stacking_faults/coeffs_subset_2.csv'\n",
    "g3 = '/home/f/PhD/ace_pot/five_models_stacking_faults/coeffs_subset_3.csv'\n",
    "g4 = '/home/f/PhD/ace_pot/five_models_stacking_faults/coeffs_subset_4.csv'\n",
    "g5 = '/home/f/PhD/ace_pot/five_models_stacking_faults/coeffs_subset_5.csv'\n",
    "\n",
    "initialize_julia(python_path)  # pass your python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = ACEpotentials(model_path) #This is specifically and ace calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = bulk('Ti', 'hcp', a=2.7,c=4.6)\n",
    "struct.calc = calculator\n",
    "print(struct.get_potential_energy())\n",
    "#if there is an output, mean model is working!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51df698",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Hello, this is for stacking faults: the set up has been complete and the following is going to be done:\n",
    "\n",
    "    We are going to analyse a few different stacking faults: Namely: Basal, Pris 1, Pris 2, Pyrm 1, Pyrm 2\n",
    "\n",
    "    1. Create Gamma surface for each trained on basal stacking:\n",
    "    2. sample 10 points using LHC sampling, and perturb the system each sample found\n",
    "    3. Run DFT on these configs\n",
    "    4. Use those to make better ACE model\n",
    "    5. Look at the difference between just using the Connors data base and the stacking fault informed one\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import qmc\n",
    "from scipy.interpolate import griddata\n",
    "def create_lhc_mesh(dimensions=2, samples=20):\n",
    "    \"\"\"\n",
    "    Create a Latin Hypercube Sampling (LHS) mesh.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dimensions : int\n",
    "        Number of dimensions (2 for a 10x10 grid).\n",
    "    samples : int\n",
    "        Number of sample points (10x10 = 100).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Array of shape (samples, dimensions) containing LHS mesh points.\n",
    "    \"\"\"\n",
    "    sampler = qmc.LatinHypercube(d=dimensions)\n",
    "    lhc = sampler.random(n=samples)\n",
    "    \n",
    "    # Scale to [0,10] for a 10x10 grid\n",
    "    mesh = qmc.scale(lhc, [0, 0], [1, 1])\n",
    "    return mesh\n",
    "\n",
    "def I2_mesh_shear(bulk,v1,v2):\n",
    "\n",
    "    # Create a mesh of stacking fault configurations (unrelaxed)\n",
    "    v1 = np.array(v1).flatten()\n",
    "    v2 = np.array(v2).flatten()\n",
    "    mesh_width = 10\n",
    "    original_cell = bulk.cell.copy()\n",
    "    # Clear or initialize the output file\n",
    "    # output_file='path.xyz'\n",
    "    # output_dir = 'gamma_surface'\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "    # Clear or initialize the output file\n",
    "    # open(output_file, 'w').close()\n",
    "    count = 0\n",
    "    original_cell = bulk.cell.copy()\n",
    "    energy_grid = np.zeros((mesh_width, mesh_width))\n",
    "    images = []\n",
    "    for i in range(mesh_width):\n",
    "        for j in range(mesh_width):\n",
    "            shift = (i / (mesh_width - 1)) * v1 + (j / (mesh_width - 1)) * v2\n",
    "            \n",
    "            bulk_copy = bulk.copy()\n",
    "            bulk_copy.set_cell(original_cell)\n",
    "            bulk_copy.set_cell([bulk_copy.cell[0],bulk_copy.cell[1],bulk_copy.cell[2]+shift])\n",
    "            bulk_copy.wrap()\n",
    "            bulk_copy.calc = calculator\n",
    "\n",
    "            constraints = [FixCartesian(i, [True, True, False]) for i in range(len(bulk_copy))]\n",
    "            bulk_copy.set_constraint(constraints)\n",
    "            mask = [[False, False, False],\n",
    "                [False, False, False],\n",
    "                [False, False, True]]\n",
    "            ucf = UnitCellFilter(bulk_copy, mask= mask)\n",
    "\n",
    "            dyn = LBFGS(ucf)\n",
    "            dyn.run(fmax=0.01)\n",
    "            # write(output_file, bulk_copy, append=True)\n",
    "            e = bulk_copy.get_potential_energy()\n",
    "            if(i == 0 and j == 0):\n",
    "                bulk_energy = e\n",
    "            surface_size = np.linalg.norm(np.cross(bulk_copy.cell[0],bulk_copy.cell[1]))\n",
    "            energy_grid[i, j] = (e-bulk_energy)*(1000)/(J*((1e-10)**2)*surface_size)\n",
    "            images.append(bulk_copy)\n",
    "            # cell_file = os.path.join(output_dir, f\"{count}.cell\")\n",
    "            \n",
    "            count += 1\n",
    "            # write(cell_file, bulk_copy, format='castep-cell')\n",
    "\n",
    "\n",
    "            bulk_copy.calc = None\n",
    "    write(\"path.xyz\",images)\n",
    "    print(v1)\n",
    "    print(v2)\n",
    "    x = np.linspace(0, 1, mesh_width)\n",
    "    y = np.linspace(0, 1, mesh_width)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    cp = plt.contourf(X, Y, energy_grid.T, levels=50, cmap='viridis')\n",
    "    plt.colorbar(cp, label='Energy (mJ/m^2)')\n",
    "    plt.xlabel('Shift along v1 (fractional)')\n",
    "    plt.ylabel('Shift along v2 (fractional)')\n",
    "    plt.title('Stacking Fault Energy Surface')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"energy_surface_contour.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def change_calc(struct,calculator,parameters):\n",
    "    struct_copy = struct.copy()\n",
    "    struct = bulk('Ti', 'hcp', a=2.7,c=10)\n",
    "    calculator = set_params(calculator, parameters)\n",
    "    struct.calc = calculator\n",
    "    struct.get_potential_energy()\n",
    "    struct = struct_copy.copy()\n",
    "    return calculator\n",
    "\n",
    "def lhc_gamma_surface_samples(bulk,v1,v2,file_path):\n",
    "    #This works for generating samples well! Very happy with this!\n",
    "    energies = []\n",
    "    original_cell = bulk.cell.copy()\n",
    "    samples = create_lhc_mesh()\n",
    "    images = []\n",
    "    for i in range(len(samples)):\n",
    "        shift = samples[i,0] * v1 + samples[i,1]  * v2\n",
    "        \n",
    "        bulk_copy = bulk.copy()\n",
    "        bulk_copy.set_cell(original_cell)\n",
    "        bulk_copy.set_cell([bulk_copy.cell[0],bulk_copy.cell[1],bulk_copy.cell[2]+shift])\n",
    "        bulk_copy.wrap()\n",
    "        bulk_copy.calc = calculator\n",
    "        constraints = [FixCartesian(i, [True, True, False]) for i in range(len(bulk_copy))]\n",
    "        bulk_copy.set_constraint(constraints)\n",
    "        mask = [[False, False, False],\n",
    "            [False, False, False],\n",
    "            [False, False, True]]\n",
    "        ucf = UnitCellFilter(bulk_copy, mask= mask)\n",
    "\n",
    "        dyn = LBFGS(ucf)\n",
    "        dyn.run(fmax=0.001)\n",
    "        # write(output_file, bulk_copy, append=True)\n",
    "        e = bulk_copy.get_potential_energy()\n",
    "        if(i == 0):\n",
    "            bulk_energy = e\n",
    "        surface_size = np.linalg.norm(np.cross(bulk_copy.cell[0],bulk_copy.cell[1]))\n",
    "        energies.append((e-bulk_energy)*(1000)/(J*((1e-10)**2)*surface_size))\n",
    "        images.append(bulk_copy)\n",
    "        \n",
    "\n",
    "\n",
    "        bulk_copy.calc = None\n",
    "    write(file_path,images)\n",
    "    grid_x, grid_y = np.mgrid[0:1:200j, 0:1:200j]  # 200x200 grid\n",
    "\n",
    "    # interpolate scattered data onto grid\n",
    "    energy_grid = griddata(samples, energies, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "    # plot contour\n",
    "    plt.figure(figsize=(6,5))\n",
    "    cp = plt.contourf(grid_x, grid_y, energy_grid, levels=50, cmap='viridis')\n",
    "    plt.colorbar(cp, label='Energy (mJ/m^2)')\n",
    "    plt.xlabel('Shift along v1 (fractional)')\n",
    "    plt.ylabel('Shift along v2 (fractional)')\n",
    "    plt.title('Stacking Fault Energy Surface')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"energy_surface_contour.png\", dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "supercell_basal = read(\"/home/f/PhD/ace_pot/supercells/0_0_0_1.cfg\",format='cfg')\n",
    "file_path =  file_path_1\n",
    "df = pd.read_csv(file_path,header = None)\n",
    "parameters = np.array(df)\n",
    "params = parameters.ravel()\n",
    "\n",
    "calculator = change_calc(supercell_basal,calculator,params)\n",
    "supercell_basal = supercell_basal *(1,1,10)\n",
    "v1 = supercell_basal.cell[0]\n",
    "v2 = supercell_basal.cell[1]\n",
    "file_path = \"/home/f/PhD/ace_pot/lhc_gamma_surface_samples/basal.xyz\"\n",
    "lhc_gamma_surface_samples(supercell_basal,v1,v2,file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "supercell_prism_1 = read(\"/home/f/PhD/ace_pot/supercells/prism1_correct.xyz\")\n",
    "for i in range(len(supercell_prism_1)):\n",
    "    supercell_prism_1.symbols[i] = 'Ti'\n",
    "supercell_prism_1 = supercell_prism_1 *(1,1,10)\n",
    "v1 = supercell_prism_1.cell[0]\n",
    "v2 = supercell_prism_1.cell[1]\n",
    "file_path = \"/home/f/PhD/ace_pot/lhc_gamma_surface_samples/prism1_W.xyz\"\n",
    "lhc_gamma_surface_samples(supercell_prism_1,v1,v2,file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "supercell_prism_2 = read(\"/home/f/PhD/ace_pot/supercells/_-2_1_1_0.cfg\",format='cfg')\n",
    "supercell_prism_2 = supercell_prism_2 * (1,1,10)\n",
    "v1 = supercell_prism_2.cell[0]\n",
    "v2 = supercell_prism_2.cell[1]\n",
    "file_path = \"/home/f/PhD/ace_pot/lhc_gamma_surface_samples/prism2.xyz\"\n",
    "lhc_gamma_surface_samples(supercell_prism_2,v1,v2,file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48904168",
   "metadata": {},
   "outputs": [],
   "source": [
    "supercell_pyrm_1 = read(\"/home/f/PhD/ace_pot/supercells/1_0_-1_1.cfg\",format='cfg')\n",
    "supercell_pyrm_1 = supercell_pyrm_1 * (1,1,2)\n",
    "v1 = supercell_pyrm_1.cell[0]\n",
    "v2 = supercell_pyrm_1.cell[1]\n",
    "file_path = \"/home/f/PhD/ace_pot/lhc_gamma_surface_samples/pyrm1_W.xyz\"\n",
    "lhc_gamma_surface_samples(supercell_pyrm_1,v1,v2,file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ade38",
   "metadata": {},
   "outputs": [],
   "source": [
    "supercell_pyrm_2 = read(\"/home/f/PhD/ace_pot/supercells/1_1_-2_2.cfg\",format='cfg')\n",
    "supercell_pyrm_2 = supercell_pyrm_2 * (1,1,2)\n",
    "v1 = supercell_pyrm_2.cell[0]\n",
    "v2 = supercell_pyrm_2.cell[1]\n",
    "file_path = \"/home/f/PhD/ace_pot/lhc_gamma_surface_samples/pyrm2.xyz\"\n",
    "lhc_gamma_surface_samples(supercell_pyrm_2,v1,v2,file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we look at the gamma line that we can compare with the paper on the stacking faults\n",
    "\n",
    "# first we start with the with I2 stacking fault for proof of concept\n",
    "\n",
    "def create_gamma_line(bulk,slip_direction,file_name,calculator,pointer):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    # Create a mesh of stacking fault configurations (unrelaxed)\n",
    "    number_of_points = 11\n",
    "    x = np.linspace(0, 0.6, number_of_points)\n",
    "    original_cell = bulk.cell.copy()\n",
    "    original_cell = bulk.cell.copy()\n",
    "    energies = []\n",
    "    images = []\n",
    "    all_energies = []\n",
    "    all_energies_gamma = []\n",
    "    for j in range(5):\n",
    "        energies = []\n",
    "        images = []\n",
    "        if j == 0:\n",
    "            file_path = m1\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        elif j == 1:\n",
    "            file_path = m2\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        elif j == 2:\n",
    "            file_path = m3\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        elif j == 3:\n",
    "            file_path = m4\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        elif j == 4:\n",
    "            file_path = m5\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        for i in range(number_of_points):\n",
    "            shift = (slip_direction * (1/(number_of_points-1))*i)*0.6\n",
    "            \n",
    "            bulk_copy = bulk.copy()\n",
    "            bulk_copy.set_cell(original_cell)\n",
    "            bulk_copy.set_cell([bulk_copy.cell[0],bulk_copy.cell[1],bulk_copy.cell[2]+shift])\n",
    "            bulk_copy.wrap()\n",
    "            bulk_copy.calc = calculator\n",
    "\n",
    "            constraints = [FixCartesian(con, [True, True, False]) for con in range(len(bulk_copy))]\n",
    "            bulk_copy.set_constraint(constraints)\n",
    "            mask = [[False, False, False],\n",
    "                [False, False, False],\n",
    "                [False, False, True]]\n",
    "            ucf = UnitCellFilter(bulk_copy, mask= mask)\n",
    "\n",
    "            dyn = LBFGS(ucf)\n",
    "            dyn.run(fmax=0.0001)\n",
    "            # write(output_file, bulk_copy, append=True)\n",
    "            \n",
    "            #comment if not needing the castep\n",
    "\n",
    "            e = bulk_copy.get_potential_energy()\n",
    "            if(i == 0):\n",
    "                bulk_energy = e\n",
    "            surface_size = np.linalg.norm(np.cross(bulk_copy.cell[0],bulk_copy.cell[1]))\n",
    "            energies.append((e-bulk_energy)*(1000)/(J*((1e-10)**2)*surface_size))\n",
    "            images.append(bulk_copy)\n",
    "            # cell_file = os.path.join(output_dir, f\"{count}.cell\")\n",
    "            bulk_copy.calc = None\n",
    "            all_energies.append(energies)\n",
    "    \n",
    "\n",
    "\n",
    "    for j in range(5):\n",
    "        energies = []\n",
    "        images = []\n",
    "        if j == 0:\n",
    "            file_path = g1\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        elif j == 1:\n",
    "            file_path = g2\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        elif j == 2:\n",
    "            file_path = g3\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        elif j == 3:\n",
    "            file_path = g4\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        elif j == 4:\n",
    "            file_path = g5\n",
    "            df = pd.read_csv(file_path,header = None)\n",
    "            parameters = np.array(df)\n",
    "            params = parameters.ravel()\n",
    "            calculator = change_calc(bulk,calculator,params)\n",
    "        for i in range(number_of_points):\n",
    "            shift = (slip_direction * (1/(number_of_points-1))*i)*0.6\n",
    "            \n",
    "            bulk_copy = bulk.copy()\n",
    "            bulk_copy.set_cell(original_cell)\n",
    "            bulk_copy.set_cell([bulk_copy.cell[0],bulk_copy.cell[1],bulk_copy.cell[2]+shift])\n",
    "            bulk_copy.wrap()\n",
    "            bulk_copy.calc = calculator\n",
    "\n",
    "            constraints = [FixCartesian(con, [True, True, False]) for con in range(len(bulk_copy))]\n",
    "            bulk_copy.set_constraint(constraints)\n",
    "            mask = [[False, False, False],\n",
    "                [False, False, False],\n",
    "                [False, False, True]]\n",
    "            ucf = UnitCellFilter(bulk_copy, mask= mask)\n",
    "\n",
    "            dyn = LBFGS(ucf)\n",
    "            dyn.run(fmax=0.0001)\n",
    "            # write(output_file, bulk_copy, append=True)\n",
    "            \n",
    "            #comment if not needing the castep\n",
    "\n",
    "            e = bulk_copy.get_potential_energy()\n",
    "            if(i == 0):\n",
    "                bulk_energy = e\n",
    "            surface_size = np.linalg.norm(np.cross(bulk_copy.cell[0],bulk_copy.cell[1]))\n",
    "            energies.append((e-bulk_energy)*(1000)/(J*((1e-10)**2)*surface_size))\n",
    "            images.append(bulk_copy)\n",
    "            # cell_file = os.path.join(output_dir, f\"{count}.cell\")\n",
    "            bulk_copy.calc = None\n",
    "            all_energies_gamma.append(energies)\n",
    "\n",
    "\n",
    "\n",
    "    all_energies = np.array(all_energies) \n",
    "    mean_energies = np.mean(all_energies, axis=0)\n",
    "    std_energies = np.std(all_energies, axis=0)\n",
    "    plt.plot(x, mean_energies, label=\"no_defects Mean\", color=\"blue\")\n",
    "    plt.fill_between(x,\n",
    "                     mean_energies - std_energies,\n",
    "                     mean_energies + std_energies,\n",
    "                     alpha=0.3, color=\"blue\", label=\"±1 std (no_defects)\")\n",
    "    \n",
    "    all_energies_gamma = np.array(all_energies_gamma) \n",
    "    mean_energies = np.mean(all_energies_gamma, axis=0)\n",
    "    std_energies = np.std(all_energies_gamma, axis=0)\n",
    "    plt.plot(x, mean_energies, label=\"gamma_informed Mean\", color=\"red\")\n",
    "    plt.fill_between(x,\n",
    "                     mean_energies - std_energies,\n",
    "                     mean_energies + std_energies,\n",
    "                     alpha=0.3, color=\"red\", label=\"±1 std (gamma_informed)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.read_csv(\"data_points_gamma_lines.csv\", header=None, names=[\"x\", \"y\"])\n",
    "\n",
    "    # Extract only the y values (second column)\n",
    "    y_values = df[\"y\"].tolist()\n",
    "\n",
    "    # Break into 4 groups of 11 consecutive points\n",
    "    groups = [y_values[i:i+11] for i in range(0, 44, 11)]\n",
    "    plt.plot(x,groups[pointer], '-o',label = \"Literature (Vasp Relaxed)\",color = \"green\")\n",
    "    \n",
    "\n",
    "    #Now we extra DFT along the gamma line that we have!\n",
    "    images = read(\"my_and_connor.xyz\", index=\":\")\n",
    "    qm_energies = [atoms.info.get(\"QM_energy\") for atoms in images]\n",
    "    qm_energies_plot = []\n",
    "    qm_energies_plot.append(0)\n",
    "    for e in qm_energies[6970+pointer*10:6980+pointer*10]:\n",
    "        qm_energies_plot.append((e-bulk_energy)*(1000)/(J*((1e-10)**2)*surface_size))\n",
    "    plt.plot(x, qm_energies_plot, '-o', label=\"DFT (Relaxed with ACE)\",color = \"orange\")\n",
    "\n",
    "\n",
    "    basal_I2_point =  (-63753.43641938  - bulk_energy)*(1000)/(J*((1e-10)**2)*surface_size)\n",
    "    prism1_point = (-63753.39751906- bulk_energy)*(1000)/(J*((1e-10)**2)*surface_size)\n",
    "    pyrm1_point  = (-82879.43240445- bulk_energy)*(1000)/(J*((1e-10)**2)*surface_size)\n",
    "    pyrm2_point =  (-89254.25363093- bulk_energy)*(1000)/(J*((1e-10)**2)*surface_size)\n",
    "    if pointer == 1:\n",
    "        plt.scatter(x[8], prism1_point, color=\"black\", marker=\"D\", \n",
    "                label=\"Relaxed Reference Point\", zorder=10)\n",
    "    elif pointer == 2:\n",
    "        plt.scatter(x[8], pyrm1_point, color=\"black\", marker=\"D\", \n",
    "                    label=\"Relaxed Reference Point\", zorder=10)\n",
    "    elif pointer == 3:\n",
    "        plt.scatter(x[7], pyrm2_point, color=\"black\", marker=\"D\", \n",
    "                    label=\"Relaxed Reference Point\", zorder=10)\n",
    "\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(r'mJ/m$^2$', fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.grid(True, ls=\"--\", alpha=0.6)\n",
    "    if pointer == 0 or pointer == 1:\n",
    "        plt.legend(fontsize = 15)\n",
    "    plt.savefig(\"energy_surface_contour.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supercell_basal = read(\"/home/f/PhD/ace_pot/supercells/0_0_0_1.cfg\",format='cfg')\n",
    "# #file_path = '/home/f/PhD/ace_pot/5_models/model_1.csv'\n",
    "# file_path = file_path_1\n",
    "# df = pd.read_csv(file_path,header = None)\n",
    "# parameters = np.array(df)\n",
    "# params = parameters.ravel()\n",
    "# calculator = change_calc(supercell_basal,calculator,params)\n",
    "\n",
    "# supercell_basal = supercell_basal *(1,1,10)\n",
    "# slip_vec = np.array([-4.4085,2.54524866,0])\n",
    "\n",
    "# create_gamma_line(supercell_basal,slip_vec)\n",
    "\n",
    "# supercell_basal = read(\"/home/f/PhD/ace_pot/supercells/0_0_0_1.cfg\",format='cfg')\n",
    "# #file_path = '/home/f/PhD/ace_pot/5_models/model_1.csv'\n",
    "# file_path = file_path_2\n",
    "# df = pd.read_csv(file_path,header = None)\n",
    "# parameters = np.array(df)\n",
    "# params = parameters.ravel()\n",
    "# calculator = change_calc(supercell_basal,calculator,params)\n",
    "\n",
    "# supercell_basal = supercell_basal *(1,1,10)\n",
    "# slip_vec = np.array([-4.4085,2.54524866,0])\n",
    "\n",
    "# create_gamma_line(supercell_basal,slip_vec,\"gamma_line_basal.xyz\")\n",
    "\n",
    "supercell_basal = read(\"/home/f/PhD/ace_pot/supercells/0_0_0_1.cfg\",format='cfg')\n",
    "#file_path = '/home/f/PhD/ace_pot/5_models/model_1.csv'\n",
    "file_path = file_path_3\n",
    "df = pd.read_csv(file_path,header = None)\n",
    "parameters = np.array(df)\n",
    "params = parameters.ravel()\n",
    "calculator = change_calc(supercell_basal,calculator,params)\n",
    "\n",
    "supercell_basal = supercell_basal *(1,1,20)\n",
    "slip_vec = np.array([-4.4085,2.54524866,0])\n",
    "\n",
    "create_gamma_line(supercell_basal,slip_vec,\"gamma_line_basal.xyz\",calculator,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prism 1 gamma\n",
    "# file_path = file_path_1\n",
    "# df = pd.read_csv(file_path,header = None)\n",
    "# parameters = np.array(df)\n",
    "# params = parameters.ravel()\n",
    "# calculator = change_calc(supercell_basal,calculator,params)\n",
    "# supercell_prism_1 = read(\"/home/f/PhD/ace_pot/supercells/prism1_correct.xyz\")\n",
    "# for i in range(len(supercell_prism_1)):\n",
    "#     supercell_prism_1.symbols[i] = 'Ti'\n",
    "# supercell_prism_1 = supercell_prism_1 *(1,1,10)\n",
    "# slip_vec = np.array([0,2.939,0])\n",
    "# create_gamma_line(supercell_prism_1,slip_vec)\n",
    "\n",
    "\n",
    "# file_path = file_path_2\n",
    "# df = pd.read_csv(file_path,header = None)\n",
    "# parameters = np.array(df)\n",
    "# params = parameters.ravel()\n",
    "# calculator = change_calc(supercell_basal,calculator,params)\n",
    "# supercell_prism_1 = read(\"/home/f/PhD/ace_pot/supercells/prism1_correct.xyz\")\n",
    "# for i in range(len(supercell_prism_1)):\n",
    "#     supercell_prism_1.symbols[i] = 'Ti'\n",
    "# supercell_prism_1 = supercell_prism_1 *(1,1,10)\n",
    "# slip_vec = np.array([0,2.939,0])\n",
    "# create_gamma_line(supercell_prism_1,slip_vec,\"gamma_line_prism1.xyz\")\n",
    "\n",
    "file_path = file_path_3\n",
    "df = pd.read_csv(file_path,header = None)\n",
    "parameters = np.array(df)\n",
    "params = parameters.ravel()\n",
    "calculator = change_calc(supercell_basal,calculator,params)\n",
    "supercell_prism_1 = read(\"/home/f/PhD/ace_pot/supercells/prism1_correct.xyz\")\n",
    "for i in range(len(supercell_prism_1)):\n",
    "    supercell_prism_1.symbols[i] = 'Ti'\n",
    "supercell_prism_1 = supercell_prism_1 *(1,1,10)\n",
    "slip_vec = np.array([0,2.939,0])\n",
    "create_gamma_line(supercell_prism_1,slip_vec,\"gamma_line_prism1.xyz\",calculator,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d152cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slip_vec = np.array([-5.10565500,-1.41604618,0])\n",
    "slip_vec = np.array([0,5.29838652,0])\n",
    "theta = np.deg2rad(0)\n",
    "\n",
    "# 2D rotation matrix\n",
    "R = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta),  np.cos(theta)]\n",
    "])\n",
    "\n",
    "# apply rotation to x,y part\n",
    "rotated_xy = R @ slip_vec[:2]\n",
    "\n",
    "# put back into 3D (z stays the same)\n",
    "slip_vec = np.array([rotated_xy[0], rotated_xy[1], slip_vec[2]])\n",
    "\n",
    "\n",
    "# file_path = file_path_1\n",
    "# df = pd.read_csv(file_path,header = None)\n",
    "# parameters = np.array(df)\n",
    "# params = parameters.ravel()\n",
    "# calculator = change_calc(supercell_basal,calculator,params)\n",
    "# supercell_pyrm_1 = read(\"/home/f/PhD/ace_pot/supercells/1_0_-1_1.cfg\",format='cfg')\n",
    "# supercell_pyrm_1 = supercell_pyrm_1 * (1,1,1)\n",
    "# v1 = supercell_pyrm_1.cell[0]\n",
    "# v2 = supercell_pyrm_1.cell[1]\n",
    "# create_gamma_line(supercell_pyrm_1,-slip_vec,\"one_toeasd.xyz\")\n",
    "\n",
    "# file_path = file_path_2\n",
    "# df = pd.read_csv(file_path,header = None)\n",
    "# parameters = np.array(df)\n",
    "# params = parameters.ravel()\n",
    "# calculator = change_calc(supercell_basal,calculator,params)\n",
    "# supercell_pyrm_1 = read(\"/home/f/PhD/ace_pot/supercells/1_0_-1_1.cfg\",format='cfg')\n",
    "# supercell_pyrm_1 = supercell_pyrm_1 * (1,1,1)\n",
    "# v1 = supercell_pyrm_1.cell[0]\n",
    "# v2 = supercell_pyrm_1.cell[1]\n",
    "\n",
    "\n",
    "\n",
    "# print(slip_vec)\n",
    "\n",
    "\n",
    "\n",
    "# create_gamma_line(supercell_pyrm_1,-slip_vec,\"gamma_line_pyrm1.xyz\")\n",
    "\n",
    "# file_path = file_path_3\n",
    "# df = pd.read_csv(file_path,header = None)\n",
    "# parameters = np.array(df)\n",
    "# params = parameters.ravel()\n",
    "# calculator = change_calc(supercell_basal,calculator,params)\n",
    "supercell_pyrm_1 = read(\"/home/f/PhD/ace_pot/supercells/1_0_-1_1.cfg\",format='cfg')\n",
    "supercell_pyrm_1 = supercell_pyrm_1 * (1,1,2)\n",
    "v1 = supercell_pyrm_1.cell[0]\n",
    "v2 = supercell_pyrm_1.cell[1]\n",
    "# slip_vec = np.array([-5.10565500,-1.41604618,0])\n",
    "create_gamma_line(supercell_pyrm_1,slip_vec,\"gamma_line_pyrm1.xyz\",calculator,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = file_path_1\n",
    "# df = pd.read_csv(file_path,header = None)\n",
    "# parameters = np.array(df)\n",
    "# params = parameters.ravel()\n",
    "# calculator = change_calc(supercell_basal,calculator,params)\n",
    "# supercell_pyrm_2 = read(\"/home/f/PhD/ace_pot/supercells/1_1_-2_2.cfg\",format='cfg')\n",
    "# supercell_pyrm_2 = supercell_pyrm_2 * (1,1,1)\n",
    "# v1 = supercell_pyrm_2.cell[0]\n",
    "# v2 = supercell_pyrm_2.cell[1]\n",
    "# slip_vec = np.array([0,5.49839340,0])\n",
    "# create_gamma_line(supercell_pyrm_2,-slip_vec,\"gamma_line_pyrm2.xyz\")\n",
    "\n",
    "# file_path = file_path_2\n",
    "# df = pd.read_csv(file_path,header = None)\n",
    "# parameters = np.array(df)\n",
    "# params = parameters.ravel()\n",
    "# calculator = change_calc(supercell_basal,calculator,params)\n",
    "# supercell_pyrm_2 = read(\"/home/f/PhD/ace_pot/supercells/1_1_-2_2.cfg\",format='cfg')\n",
    "# supercell_pyrm_2 = supercell_pyrm_2 * (1,1,1)\n",
    "# v1 = supercell_pyrm_2.cell[0]\n",
    "# v2 = supercell_pyrm_2.cell[1]\n",
    "# slip_vec = np.array([0,5.49839340,0])\n",
    "# create_gamma_line(supercell_pyrm_2,-slip_vec,\"gamma_line_pyrm2.xyz\")\n",
    "\n",
    "file_path = file_path_3\n",
    "df = pd.read_csv(file_path,header = None)\n",
    "parameters = np.array(df)\n",
    "params = parameters.ravel()\n",
    "calculator = change_calc(supercell_basal,calculator,params)\n",
    "supercell_pyrm_2 = read(\"/home/f/PhD/ace_pot/supercells/1_1_-2_2.cfg\",format='cfg')\n",
    "supercell_pyrm_2 = supercell_pyrm_2 * (1,1,2)\n",
    "v1 = supercell_pyrm_2.cell[0]\n",
    "v2 = supercell_pyrm_2.cell[1]\n",
    "slip_vec = np.array([0,5.49839340,0])\n",
    "create_gamma_line(supercell_pyrm_2,-slip_vec,\"gamma_line_pyrm2.xyz\",calculator,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This computes the average max force and average RMS force per gamma line\n",
    "images = read(\"my_and_connor.xyz\", index=\":\")\n",
    "num_configs = len(images)\n",
    "print(\"Number of Structures: \", num_configs)\n",
    "\n",
    "qm_forces = [atoms.arrays[\"QM_forces\"] for atoms in images]\n",
    "\n",
    "\n",
    "\n",
    "max_force_avgs = []\n",
    "rms_force_avgs = []\n",
    "\n",
    "\n",
    "gamma_line_forces = qm_forces[7146:7155]  # list of arrays\n",
    "\n",
    "max_forces = []\n",
    "rms_forces = []\n",
    "\n",
    "for f in gamma_line_forces:  # f is (N_atoms, 3)\n",
    "    z_forces = f[:, 2]  # take only z-component\n",
    "    max_forces.append(np.max(np.abs(z_forces)))   # max |Fz| in structure\n",
    "    rms_forces.append(np.sqrt(np.mean(z_forces**2)))  # RMS of Fz in structure\n",
    "\n",
    "max_force_avg = np.mean(max_forces)\n",
    "rms_force_avg = np.mean(rms_forces)\n",
    "\n",
    "max_force_avgs.append(max_force_avg)\n",
    "rms_force_avgs.append(rms_force_avg)\n",
    "\n",
    "print(f\"Pointer {i}: Avg Max Fz = {max_force_avg:.6f}, Avg RMS Fz = {rms_force_avg:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
